
# DataFlowX-Modern-ELT-Pipeline-with-dbt-Snowflake-Airflow
DataFlowX is a hands-on, end-to-end ELT pipeline built using dbt, Snowflake, and Apache Airflow, showcasing the backbone of a modern data engineering stack.


Overview - 
DataFlowX demonstrates how to design and deploy a modern ELT (Extract â†’ Load â†’ Transform) data pipeline using cloud-native and open-source tools.

ğŸ§© Key Features -

âœ… End-to-end ELT Workflow â€“ from raw ingestion to analytics-ready data marts

ğŸ§  Data Modeling â€“ staging, fact, and mart layers using dbt best practices

âš™ï¸ Automated Orchestration â€“ dbt transformations triggered via Airflow DAGs

ğŸ” Snowflake RBAC Setup â€“ role-based access control for secure warehouse access

ğŸ§ª Data Quality Tests â€“ generic and singular tests using dbt

ğŸ§° Modular Architecture â€“ easily extensible for real-world data sources

Architecture Diagram - 

          +-------------------+
          |   Source Data     |
          +-------------------+
                    |
                    â–¼
        +----------------------+
        |   Snowflake Stage    |
        +----------------------+
                    |
                    â–¼
        +----------------------+
        |     dbt Models       |
        | (Staging â†’ Fact â†’ Mart)
        +----------------------+
                    |
                    â–¼
        +----------------------+
        | Airflow Orchestration|
        +----------------------+
                    |
                    â–¼
        +----------------------+
        |   Analytics Layer    |
        +----------------------+
Tech Stack -

Layer	Tool	Purpose
ğŸ­ Data Warehouse	Snowflake	Central data storage and compute

ğŸ§± Transformation	dbt Core	SQL-based modular transformation and testing

â° Orchestration	Apache Airflow	Workflow scheduling and automation

ğŸ³ Infrastructure	Docker (optional)	Containerized environment

ğŸ“Š Visualization	dbt Docs / Airflow UI	Lineage & monitoring


ğŸš€ Setup & Execution - 

1ï¸âƒ£ Setup Snowflake & dbt

Create a Snowflake database, warehouse, and roles

Configure your dbt profile

pip install dbt-snowflake
dbt init dataflowx


Update your profiles.yml:

target: dev
outputs:
  dev:
    type: snowflake
    account: <account_id>
    user: <user_name>
    password: <password>
    role: TRANSFORMER
    database: DATAFLOWX
    warehouse: COMPUTE_WH
    schema: DBT_DEV

2ï¸âƒ£ Configure dbt Project - 
Edit dbt_project.yml and install dependencies:

dbt deps


Run dbt models:

dbt run
dbt test

3ï¸âƒ£ Orchestrate with Airflow - 
Deploy the DAG in your Airflow instance:

airflow dags list
airflow dags trigger dbt_dataflowx_dag


Optionally, run with Docker:

docker-compose up

ğŸ“Š Results - 

ğŸ”„ Data successfully transformed from raw â†’ staging â†’ marts

âœ… dbt models tested and validated

â° Airflow DAGs running daily on schedule

ğŸ” Snowflake RBAC implemented for secure data access

Credits & References -

Credit to the original video author for educational inspiration.

https://youtu.be/OLXkGB7krGo?si=2g7NTtzjFCzjDJZT


